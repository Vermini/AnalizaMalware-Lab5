{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Wykrywanie anomalii sieciowych\n",
    "\n",
    "## Zadanie\n",
    "\n",
    "Wytrenowaƒá autoenkoder na za≈Çaczonych dnaych pomiarowych z sieic AGH. Paietaƒá, ≈ºe dane to szereg czasowy i autoenkoder trenujemy na oknie o romiarze $w$. Zbudowanie PCA tez bƒôdzie unznane, ale na najnizsza ocene umo≈ºliwiajƒÖca zaliczenie.\n",
    "\n",
    "Uwagi\n",
    "\n",
    "- G≈Ç√≥wne etapy analizy powinny byc rodzieleone na kom√≥rki\n",
    "- RozwiƒÖzanie przysy≈Çamy w formie notatnika z wynikami\n",
    "- Nale≈ºy skomentowaƒá podjete akcje\n",
    "\n",
    "## Dane grupy\n",
    "\n",
    "- Karol Mierzwi≈Ñski\n",
    "- Micha≈Ç Fidelus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krok 1: Importowanie bibliotek\n",
    "Najpierw zaimportujemy potrzebne biblioteki. Bƒôdziemy korzystaƒá z bibliotek takich jak numpy, pandas, matplotlib oraz tensorflow do budowy i treningu modelu autoenkodera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krok 2: Wczytanie danych\n",
    "Za≈Çadujemy dane pomiarowe z pliku CSV. Upewnimy siƒô, ≈ºe dane sƒÖ poprawnie wczytane i sprawdzimy podstawowe statystyki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp  b6-ucirtr  ucirtr-b6   b6-b1rtr  b1rtr-b6  b1-ftjrtr  \\\n",
      "0  2020-12-13 15:25:03  4063963.0  2099589.0  1728848.0   52632.0     2352.0   \n",
      "1  2020-12-13 15:30:03  4115472.0  2033890.0  1675340.0   46513.0     2468.0   \n",
      "2  2020-12-13 15:35:03  4460894.0  1967785.0  1717643.0   46969.0     2572.0   \n",
      "3  2020-12-13 15:40:03  4180486.0  2008196.0  1616511.0   47048.0     2451.0   \n",
      "4  2020-12-13 15:45:03  3744176.0  3335874.0  1746441.0   56408.0     2834.0   \n",
      "\n",
      "   ftjrtr-b1  cyfronet-ucirtr  ucirtr-cyfronet  ftj-b6rtr  ...  ftj-ucirtr  \\\n",
      "0    16766.0       10425570.0       39459770.0    82891.0  ...   5046928.0   \n",
      "1    17191.0       11739436.0       37856957.0    29267.0  ...   5468130.0   \n",
      "2    17776.0       14880181.0       22968938.0    19467.0  ...   4910226.0   \n",
      "3    16932.0       13961237.0       23170350.0    24386.0  ...   5883441.0   \n",
      "4    17673.0       14983896.0       24006404.0    29554.0  ...   4670566.0   \n",
      "\n",
      "   ucirtr-ftj  uci-ftjrtr  ftjrtr-uci  uci-b1rtr  b1rtr-uci  ftj-b1rtr  \\\n",
      "0   1831919.0   1845690.0   5044319.0  8395469.0  2898609.0    16534.0   \n",
      "1   1557696.0   1562774.0   5506855.0  8389581.0  3139075.0    17260.0   \n",
      "2   1682946.0   1674507.0   4880848.0  7446018.0  2968990.0    17838.0   \n",
      "3   2946501.0   2943126.0   5899514.0  7788634.0  4172991.0    16892.0   \n",
      "4   2467885.0   2503704.0   4727394.0  7436740.0  3538008.0    17450.0   \n",
      "\n",
      "   b1rtr-ftj  uci-b6rtr  b6rtr-uci  \n",
      "0     2314.0  2104685.0  4062125.0  \n",
      "1     2481.0  2033834.0  4113483.0  \n",
      "2     2586.0  1960732.0  4464048.0  \n",
      "3     2439.0  2014920.0  4178625.0  \n",
      "4     2797.0  3334540.0  3739133.0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "          b6-ucirtr     ucirtr-b6      b6-b1rtr      b1rtr-b6     b1-ftjrtr  \\\n",
      "count  1.028500e+05  1.028500e+05  1.028500e+05  1.028500e+05  1.028500e+05   \n",
      "mean   3.877078e+06  7.377718e+06  3.138792e+05  2.633845e+05  6.666573e+03   \n",
      "std    7.189350e+06  8.946404e+06  8.607069e+05  1.230969e+06  5.140814e+04   \n",
      "min    1.965240e+05  2.172590e+05  1.140000e+02  3.340000e+02  0.000000e+00   \n",
      "25%    7.836155e+05  2.287284e+06  2.790000e+03  4.499225e+04  2.318000e+03   \n",
      "50%    1.440072e+06  3.712098e+06  7.723500e+03  7.225400e+04  2.591000e+03   \n",
      "75%    3.789276e+06  9.072136e+06  1.395890e+05  1.069798e+05  3.756000e+03   \n",
      "max    1.130128e+08  1.834500e+08  6.337099e+07  4.973782e+07  1.054514e+07   \n",
      "\n",
      "          ftjrtr-b1  cyfronet-ucirtr  ucirtr-cyfronet     ftj-b6rtr  \\\n",
      "count  1.028500e+05     1.028500e+05     1.028500e+05  1.028500e+05   \n",
      "mean   6.820542e+04     3.258460e+07     1.777478e+07  7.918541e+04   \n",
      "std    2.734346e+05     3.350270e+07     1.452646e+07  5.321836e+05   \n",
      "min    0.000000e+00     1.437898e+06     1.141230e+06  5.971000e+03   \n",
      "25%    1.853200e+04     9.327398e+06     6.950077e+06  1.445800e+04   \n",
      "50%    2.052700e+04     1.809765e+07     1.341228e+07  1.845150e+04   \n",
      "75%    2.985200e+04     4.473082e+07     2.472002e+07  3.779200e+04   \n",
      "max    1.155060e+07     5.172031e+08     1.703898e+08  3.405389e+07   \n",
      "\n",
      "          b6rtr-ftj  ...    ftj-ucirtr    ucirtr-ftj    uci-ftjrtr  \\\n",
      "count  1.028500e+05  ...  1.028500e+05  1.028500e+05  1.028500e+05   \n",
      "mean   7.657341e+03  ...  4.738635e+06  9.865929e+06  9.865942e+06   \n",
      "std    8.368003e+04  ...  4.488339e+06  1.235602e+07  1.235711e+07   \n",
      "min    5.000000e+01  ...  4.920490e+05  1.421080e+05  1.406040e+05   \n",
      "25%    1.780000e+02  ...  2.520984e+06  1.299862e+06  1.299831e+06   \n",
      "50%    5.380000e+02  ...  3.695662e+06  3.944535e+06  3.939593e+06   \n",
      "75%    2.113000e+03  ...  5.467507e+06  1.565501e+07  1.564927e+07   \n",
      "max    1.118200e+07  ...  1.143445e+08  4.243374e+08  4.242844e+08   \n",
      "\n",
      "         ftjrtr-uci     uci-b1rtr     b1rtr-uci     ftj-b1rtr     b1rtr-ftj  \\\n",
      "count  1.028500e+05  1.028500e+05  1.028500e+05  1.028500e+05  1.028500e+05   \n",
      "mean   4.738668e+06  1.422274e+07  3.684847e+06  6.820799e+04  6.667038e+03   \n",
      "std    4.488436e+06  1.429892e+07  4.015270e+06  2.734538e+05  5.126315e+04   \n",
      "min    4.934840e+05  3.185800e+04  1.440300e+04  6.520000e+03  1.220000e+02   \n",
      "25%    2.519829e+06  5.092956e+06  1.016617e+06  1.853400e+04  2.320000e+03   \n",
      "50%    3.694544e+06  7.793638e+06  2.025130e+06  2.052600e+04  2.593000e+03   \n",
      "75%    5.469742e+06  1.783049e+07  4.957106e+06  2.985700e+04  3.758000e+03   \n",
      "max    1.154116e+08  2.185796e+08  1.008982e+08  1.151727e+07  1.054513e+07   \n",
      "\n",
      "          uci-b6rtr     b6rtr-uci  \n",
      "count  1.028500e+05  1.028500e+05  \n",
      "mean   7.377706e+06  3.877079e+06  \n",
      "std    8.946782e+06  7.189173e+06  \n",
      "min    2.167860e+05  1.958000e+05  \n",
      "25%    2.286274e+06  7.834212e+05  \n",
      "50%    3.711433e+06  1.440175e+06  \n",
      "75%    9.072715e+06  3.789208e+06  \n",
      "max    1.835803e+08  1.125814e+08  \n",
      "\n",
      "[8 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Wczytanie danych z pliku CSV\n",
    "data = pd.read_csv('./../data/stats_clean.csv')\n",
    "\n",
    "# Wy≈õwietlenie pierwszych kilku wierszy danych\n",
    "print(data.head())\n",
    "\n",
    "# Sprawdzenie podstawowych statystyk\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krok 3: Przygotowanie danych\n",
    "Dane muszƒÖ zostaƒá przeskalowane i podzielone na okna czasowe o rozmiarze \n",
    "ùë§\n",
    "w. U≈ºyjemy StandardScaler do normalizacji danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ustawienie rozmiaru okna\n",
    "window_size = 10\n",
    "\n",
    "# Normalizacja danych\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Tworzenie okien czasowych\n",
    "def create_windows(data, window_size):\n",
    "    windows = []\n",
    "    for i in range(len(data) - window_size + 1):\n",
    "        windows.append(data[i:i+window_size])\n",
    "    return np.array(windows)\n",
    "\n",
    "data_windows = create_windows(data_scaled, window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krok 4: Budowa modelu autoenkodera\n",
    "Zbudujemy autoenkoder sk≈ÇadajƒÖcy siƒô z warstwy wej≈õciowej, kilku warstw ukrytych (encoder) oraz kilku warstw ukrytych (decoder). Na ko≈Ñcu mamy warstwƒô wyj≈õciowƒÖ o takim samym rozmiarze jak warstwa wej≈õciowa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = data_windows.shape[1] * data_windows.shape[2]\n",
    "encoding_dim = 32\n",
    "\n",
    "# Definicja modelu autoenkodera\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krok 5: Trenowanie modelu\n",
    "Podzielimy dane na zestawy treningowe i walidacyjne. Nastƒôpnie przeszkolimy model, u≈ºywajƒÖc wczesnego zatrzymania (early stopping), aby uniknƒÖƒá przeuczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotowanie danych treningowych i walidacyjnych\n",
    "X = data_windows.reshape((data_windows.shape[0], input_dim))\n",
    "X_train, X_val = X[:int(len(X)*0.8)], X[int(len(X)*0.8):]\n",
    "\n",
    "# Trenowanie modelu\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = autoencoder.fit(X_train, X_train, \n",
    "                          epochs=100, \n",
    "                          batch_size=32, \n",
    "                          validation_data=(X_val, X_val),\n",
    "                          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krok 6: Ocena modelu i wykrywanie anomalii\n",
    "Po treningu modelu, obliczymy b≈ÇƒÖd rekonstrukcji dla danych treningowych i walidacyjnych. Wykorzystamy ten b≈ÇƒÖd do zidentyfikowania anomalii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obliczenie b≈Çƒôdu rekonstrukcji\n",
    "reconstructed_train = autoencoder.predict(X_train)\n",
    "reconstructed_val = autoencoder.predict(X_val)\n",
    "\n",
    "mse_train = np.mean(np.power(X_train - reconstructed_train, 2), axis=1)\n",
    "mse_val = np.mean(np.power(X_val - reconstructed_val, 2), axis=1)\n",
    "\n",
    "# Ustalenie progu anomalii\n",
    "threshold = np.mean(mse_train) + 3*np.std(mse_train)\n",
    "\n",
    "# Wykrywanie anomalii\n",
    "anomalies = mse_val > threshold\n",
    "\n",
    "# Wizualizacja anomalii\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mse_val, label='MSE Validation')\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label='Anomaly Threshold')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Anomaly Detection')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podsumowanie\n",
    "W tym projekcie przeszkolili≈õmy autoenkoder na danych pomiarowych z sieci AGH, aby wykrywaƒá anomalie. Wykorzystali≈õmy normalizacjƒô danych, podzia≈Ç na okna czasowe oraz metody wykrywania anomalii na podstawie b≈Çƒôdu rekonstrukcji. Autoenkodery sƒÖ potƒô≈ºnym narzƒôdziem do analizy szereg√≥w czasowych i wykrywania nietypowych wzorc√≥w w danych."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
