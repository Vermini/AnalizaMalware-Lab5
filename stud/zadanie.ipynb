{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Wykrywanie anomalii sieciowych\n",
    "\n",
    "## Zadanie\n",
    "\n",
    "Wytrenowa autoenkoder na zaaczonych dnaych pomiarowych z sieic AGH. Paieta, 偶e dane to szereg czasowy i autoenkoder trenujemy na oknie o romiarze $w$. Zbudowanie PCA tez bdzie unznane, ale na najnizsza ocene umo偶liwiajca zaliczenie.\n",
    "\n",
    "Uwagi\n",
    "\n",
    "- G贸wne etapy analizy powinny byc rodzieleone na kom贸rki\n",
    "- Rozwizanie przysyamy w formie notatnika z wynikami\n",
    "- Nale偶y skomentowa podjete akcje\n",
    "\n",
    "## Dane grupy\n",
    "\n",
    "- Karol Mierzwiski\n",
    "- Micha Fidelus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krok 1: Importowanie bibliotek\n",
    "Najpierw zaimportujemy potrzebne biblioteki. Bdziemy korzysta z bibliotek takich jak numpy, pandas, matplotlib oraz tensorflow do budowy i treningu modelu autoenkodera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krok 2: Wczytanie danych\n",
    "Zaadujemy dane pomiarowe z pliku CSV. Upewnimy si, 偶e dane s poprawnie wczytane i sprawdzimy podstawowe statystyki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp  b6-ucirtr  ucirtr-b6   b6-b1rtr  b1rtr-b6  b1-ftjrtr  \\\n",
      "0  2020-12-13 15:25:03  4063963.0  2099589.0  1728848.0   52632.0     2352.0   \n",
      "1  2020-12-13 15:30:03  4115472.0  2033890.0  1675340.0   46513.0     2468.0   \n",
      "2  2020-12-13 15:35:03  4460894.0  1967785.0  1717643.0   46969.0     2572.0   \n",
      "3  2020-12-13 15:40:03  4180486.0  2008196.0  1616511.0   47048.0     2451.0   \n",
      "4  2020-12-13 15:45:03  3744176.0  3335874.0  1746441.0   56408.0     2834.0   \n",
      "\n",
      "   ftjrtr-b1  cyfronet-ucirtr  ucirtr-cyfronet  ftj-b6rtr  ...  ftj-ucirtr  \\\n",
      "0    16766.0       10425570.0       39459770.0    82891.0  ...   5046928.0   \n",
      "1    17191.0       11739436.0       37856957.0    29267.0  ...   5468130.0   \n",
      "2    17776.0       14880181.0       22968938.0    19467.0  ...   4910226.0   \n",
      "3    16932.0       13961237.0       23170350.0    24386.0  ...   5883441.0   \n",
      "4    17673.0       14983896.0       24006404.0    29554.0  ...   4670566.0   \n",
      "\n",
      "   ucirtr-ftj  uci-ftjrtr  ftjrtr-uci  uci-b1rtr  b1rtr-uci  ftj-b1rtr  \\\n",
      "0   1831919.0   1845690.0   5044319.0  8395469.0  2898609.0    16534.0   \n",
      "1   1557696.0   1562774.0   5506855.0  8389581.0  3139075.0    17260.0   \n",
      "2   1682946.0   1674507.0   4880848.0  7446018.0  2968990.0    17838.0   \n",
      "3   2946501.0   2943126.0   5899514.0  7788634.0  4172991.0    16892.0   \n",
      "4   2467885.0   2503704.0   4727394.0  7436740.0  3538008.0    17450.0   \n",
      "\n",
      "   b1rtr-ftj  uci-b6rtr  b6rtr-uci  \n",
      "0     2314.0  2104685.0  4062125.0  \n",
      "1     2481.0  2033834.0  4113483.0  \n",
      "2     2586.0  1960732.0  4464048.0  \n",
      "3     2439.0  2014920.0  4178625.0  \n",
      "4     2797.0  3334540.0  3739133.0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "          b6-ucirtr     ucirtr-b6      b6-b1rtr      b1rtr-b6     b1-ftjrtr  \\\n",
      "count  1.028500e+05  1.028500e+05  1.028500e+05  1.028500e+05  1.028500e+05   \n",
      "mean   3.877078e+06  7.377718e+06  3.138792e+05  2.633845e+05  6.666573e+03   \n",
      "std    7.189350e+06  8.946404e+06  8.607069e+05  1.230969e+06  5.140814e+04   \n",
      "min    1.965240e+05  2.172590e+05  1.140000e+02  3.340000e+02  0.000000e+00   \n",
      "25%    7.836155e+05  2.287284e+06  2.790000e+03  4.499225e+04  2.318000e+03   \n",
      "50%    1.440072e+06  3.712098e+06  7.723500e+03  7.225400e+04  2.591000e+03   \n",
      "75%    3.789276e+06  9.072136e+06  1.395890e+05  1.069798e+05  3.756000e+03   \n",
      "max    1.130128e+08  1.834500e+08  6.337099e+07  4.973782e+07  1.054514e+07   \n",
      "\n",
      "          ftjrtr-b1  cyfronet-ucirtr  ucirtr-cyfronet     ftj-b6rtr  \\\n",
      "count  1.028500e+05     1.028500e+05     1.028500e+05  1.028500e+05   \n",
      "mean   6.820542e+04     3.258460e+07     1.777478e+07  7.918541e+04   \n",
      "std    2.734346e+05     3.350270e+07     1.452646e+07  5.321836e+05   \n",
      "min    0.000000e+00     1.437898e+06     1.141230e+06  5.971000e+03   \n",
      "25%    1.853200e+04     9.327398e+06     6.950077e+06  1.445800e+04   \n",
      "50%    2.052700e+04     1.809765e+07     1.341228e+07  1.845150e+04   \n",
      "75%    2.985200e+04     4.473082e+07     2.472002e+07  3.779200e+04   \n",
      "max    1.155060e+07     5.172031e+08     1.703898e+08  3.405389e+07   \n",
      "\n",
      "          b6rtr-ftj  ...    ftj-ucirtr    ucirtr-ftj    uci-ftjrtr  \\\n",
      "count  1.028500e+05  ...  1.028500e+05  1.028500e+05  1.028500e+05   \n",
      "mean   7.657341e+03  ...  4.738635e+06  9.865929e+06  9.865942e+06   \n",
      "std    8.368003e+04  ...  4.488339e+06  1.235602e+07  1.235711e+07   \n",
      "min    5.000000e+01  ...  4.920490e+05  1.421080e+05  1.406040e+05   \n",
      "25%    1.780000e+02  ...  2.520984e+06  1.299862e+06  1.299831e+06   \n",
      "50%    5.380000e+02  ...  3.695662e+06  3.944535e+06  3.939593e+06   \n",
      "75%    2.113000e+03  ...  5.467507e+06  1.565501e+07  1.564927e+07   \n",
      "max    1.118200e+07  ...  1.143445e+08  4.243374e+08  4.242844e+08   \n",
      "\n",
      "         ftjrtr-uci     uci-b1rtr     b1rtr-uci     ftj-b1rtr     b1rtr-ftj  \\\n",
      "count  1.028500e+05  1.028500e+05  1.028500e+05  1.028500e+05  1.028500e+05   \n",
      "mean   4.738668e+06  1.422274e+07  3.684847e+06  6.820799e+04  6.667038e+03   \n",
      "std    4.488436e+06  1.429892e+07  4.015270e+06  2.734538e+05  5.126315e+04   \n",
      "min    4.934840e+05  3.185800e+04  1.440300e+04  6.520000e+03  1.220000e+02   \n",
      "25%    2.519829e+06  5.092956e+06  1.016617e+06  1.853400e+04  2.320000e+03   \n",
      "50%    3.694544e+06  7.793638e+06  2.025130e+06  2.052600e+04  2.593000e+03   \n",
      "75%    5.469742e+06  1.783049e+07  4.957106e+06  2.985700e+04  3.758000e+03   \n",
      "max    1.154116e+08  2.185796e+08  1.008982e+08  1.151727e+07  1.054513e+07   \n",
      "\n",
      "          uci-b6rtr     b6rtr-uci  \n",
      "count  1.028500e+05  1.028500e+05  \n",
      "mean   7.377706e+06  3.877079e+06  \n",
      "std    8.946782e+06  7.189173e+06  \n",
      "min    2.167860e+05  1.958000e+05  \n",
      "25%    2.286274e+06  7.834212e+05  \n",
      "50%    3.711433e+06  1.440175e+06  \n",
      "75%    9.072715e+06  3.789208e+06  \n",
      "max    1.835803e+08  1.125814e+08  \n",
      "\n",
      "[8 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Wczytanie danych z pliku CSV\n",
    "data = pd.read_csv('./../data/stats_clean.csv')\n",
    "\n",
    "# Wywietlenie pierwszych kilku wierszy danych\n",
    "print(data.head())\n",
    "\n",
    "# Sprawdzenie podstawowych statystyk\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krok 3: Przygotowanie danych\n",
    "Dane musz zosta przeskalowane i podzielone na okna czasowe o rozmiarze \n",
    "\n",
    "w. U偶yjemy StandardScaler do normalizacji danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ustawienie rozmiaru okna\n",
    "window_size = 10\n",
    "\n",
    "# Normalizacja danych\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Tworzenie okien czasowych\n",
    "def create_windows(data, window_size):\n",
    "    windows = []\n",
    "    for i in range(len(data) - window_size + 1):\n",
    "        windows.append(data[i:i+window_size])\n",
    "    return np.array(windows)\n",
    "\n",
    "data_windows = create_windows(data_scaled, window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krok 4: Budowa modelu autoenkodera\n",
    "Zbudujemy autoenkoder skadajcy si z warstwy wejciowej, kilku warstw ukrytych (encoder) oraz kilku warstw ukrytych (decoder). Na kocu mamy warstw wyjciow o takim samym rozmiarze jak warstwa wejciowa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = data_windows.shape[1] * data_windows.shape[2]\n",
    "encoding_dim = 32\n",
    "\n",
    "# Definicja modelu autoenkodera\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krok 5: Trenowanie modelu\n",
    "Podzielimy dane na zestawy treningowe i walidacyjne. Nastpnie przeszkolimy model, u偶ywajc wczesnego zatrzymania (early stopping), aby unikn przeuczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotowanie danych treningowych i walidacyjnych\n",
    "X = data_windows.reshape((data_windows.shape[0], input_dim))\n",
    "X_train, X_val = X[:int(len(X)*0.8)], X[int(len(X)*0.8):]\n",
    "\n",
    "# Trenowanie modelu\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = autoencoder.fit(X_train, X_train, \n",
    "                          epochs=100, \n",
    "                          batch_size=32, \n",
    "                          validation_data=(X_val, X_val),\n",
    "                          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krok 6: Ocena modelu i wykrywanie anomalii\n",
    "Po treningu modelu, obliczymy bd rekonstrukcji dla danych treningowych i walidacyjnych. Wykorzystamy ten bd do zidentyfikowania anomalii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obliczenie bdu rekonstrukcji\n",
    "reconstructed_train = autoencoder.predict(X_train)\n",
    "reconstructed_val = autoencoder.predict(X_val)\n",
    "\n",
    "mse_train = np.mean(np.power(X_train - reconstructed_train, 2), axis=1)\n",
    "mse_val = np.mean(np.power(X_val - reconstructed_val, 2), axis=1)\n",
    "\n",
    "# Ustalenie progu anomalii\n",
    "threshold = np.mean(mse_train) + 3*np.std(mse_train)\n",
    "\n",
    "# Wykrywanie anomalii\n",
    "anomalies = mse_val > threshold\n",
    "\n",
    "# Wizualizacja anomalii\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mse_val, label='MSE Validation')\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label='Anomaly Threshold')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Anomaly Detection')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podsumowanie\n",
    "W tym projekcie przeszkolilimy autoenkoder na danych pomiarowych z sieci AGH, aby wykrywa anomalie. Wykorzystalimy normalizacj danych, podzia na okna czasowe oraz metody wykrywania anomalii na podstawie bdu rekonstrukcji. Autoenkodery s pot偶nym narzdziem do analizy szereg贸w czasowych i wykrywania nietypowych wzorc贸w w danych."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
